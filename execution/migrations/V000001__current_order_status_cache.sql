-- These examples uses the autogenerated dataset by the ORDERS quickstart of the Confluent Datagen Connector

-- Establish the source for our data. In this case, our source is keyed by order #
-- and we will leverage ksqlDBs source tables

CREATE OR REPLACE TABLE ORDERS_CACHE (ORDER_ID_KEY VARCHAR PRIMARY KEY) WITH (KAFKA_TOPIC='order_flow', VALUE_FORMAT='AVRO', KEY_FORMAT='KAFKA');

-- We will create a materialized cache to tell us the status of a given order
-- given an order ID. We'd like to build this table from the beginning of time
-- so we set the offset reset to earliest

SET 'auto.offset.reset' = 'earliest';

CREATE OR REPLACE TABLE ORDERS_CACHE_CLEAN AS
SELECT ORDER_ID_KEY `ORDERID`
    , FROM_UNIXTIME(ORDERTIME) `ORDERTIME`
    , ITEMID `ITEMID`
    , ORDERUNITS `ORDERUNITS`
    , ADDRESS->CITY `ADDRESS_CITY`
    , ADDRESS->STATE `ADDRESS_STATE`
    , ADDRESS->ZIPCODE `ADDRESS_ZIPCODE`
FROM ORDERS_CACHE
EMIT CHANGES;
