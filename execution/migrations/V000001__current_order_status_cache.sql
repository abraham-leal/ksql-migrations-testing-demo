-- This examples uses the autogenerated dataset by the ORDERS quickstart of the Confluent Datagen Connector

-- Establish the source for our data. In this case, our source is keyed by order #
-- but we will create it as a stream to allow for future slice/dice
CREATE OR REPLACE STREAM ORDERS_FLOW WITH (KAFKA_TOPIC='order_flow', VALUE_FORMAT='AVRO');

-- We will create a materialized cache to tell us the status of a given order
-- given an order ID. We'd like to build this table from the beginning of time
-- so we set the offset reset

SET 'auto.offset.reset' = 'earliest';

CREATE OR REPLACE TABLE ORDER_CACHE AS
SELECT ORDERID `ORDERID`
    , LATEST_BY_OFFSET(ORDERTIME) `ORDERTIME`
    , LATEST_BY_OFFSET(ITEMID) `ITEMID`
    , LATEST_BY_OFFSET(ORDERUNITS) `ORDERUNITS`
    , LATEST_BY_OFFSET(ADDRESS->CITY) `ADDRESS_CITY`
    , LATEST_BY_OFFSET(ADDRESS->STATE) `ADDRESS_STATE`
    , LATEST_BY_OFFSET(ADDRESS->ZIPCODE) `ADDRESS_ZIPCODE`
FROM ORDERS_FLOW
GROUP BY ORDERID;
